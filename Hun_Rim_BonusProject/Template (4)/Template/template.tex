\documentclass[unicode,11pt,a4paper,oneside,numbers=endperiod,openany]{scrartcl}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{enumitem}

\newcommand{\norm}[1]{\lvert\lvert #1 \rvert\rvert}

\renewcommand{\thesubsection}{\arabic{subsection}}

\input{assignment.sty}
\begin{document}


\setassignment
\setduedate{Wednesday, 22 November 2023, 11:59 PM}

\serieheader{Numerical Computing}{2023}{\textbf{Student:} Hun Rim}{\textbf{Discussed with:} FULL NAME}{Bonus assignment}{}
\newline

\assignmentpolicy


\newpage

\section*{Exercise 1: Inconsistent systems of equations [10 points]}
Consider the following inconsistent systems of equations: \\

\begin{center}
(a) ${A_1x = b_1}$, where

\vspace{10px}

\begin{equation*}
A_1 =
\begin{bmatrix}
1 & 0 \\
1 & 0 \\
1 & 0
\end{bmatrix}
b_1=
\begin{bmatrix}
5 \\
2 \\
4
\end{bmatrix}
\end{equation*}
\end{center}

\begin{center}
(b) ${A_2x = b_2}$, where

\vspace{10px}

\begin{equation*}
A_2 =
\begin{bmatrix}
1 & 1 & 0 \\
0 & 1 & 1 \\
1 & 2 & 1 \\
1 & 0 & 1
\end{bmatrix}
b_2=
\begin{bmatrix}
2 \\
2 \\
3 \\
4
\end{bmatrix}
\end{equation*}
\end{center}

Find the least squares solution ${x^*}$ and compute the Euclidean norm of the residual, SE and RMSE. \\

\textbf{solution:} \\
Least Square solution ${x^*}$ can be obtained by solving the following equation:

\vspace{20px}

\begin{equation}
 A^TAx = A^Tb
\end{equation}

\vspace{20px}

Then from the ${x^*}$ obtained, we can get the residual vector as following and from it, we can calculate the Euclidean norm and proceed to SE (Standard Error) and RMSE (Root Mean Squared Error):

\vspace{20px}

\begin{equation}
 r = Ax^* - b
\end{equation}

\vspace{20px}

\begin{equation}
 Euclidean Norm = \norm{r}_2
\end{equation}

\vspace{20px}

\begin{equation}
 SE = \norm{r}_2^2
\end{equation}

\vspace{20px}

\begin{equation}
 RMSE = \sqrt{\frac{SE}{m}}
\end{equation}

\vspace{20px}

Where ${m}$ is the number of rows in residual vector. \\

\newpage
(a)
\begin{equation*}
\begin{bmatrix}
1 & 1 & 1 \\
0 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
1 & 0 \\
1 & 0 \\
1 & 0
\end{bmatrix}
x = \begin{bmatrix}
1 & 1 & 1 \\
0 & 0 & 0
\end{bmatrix}
\begin{bmatrix}
5 \\
2 \\
4
\end{bmatrix}
\end{equation*}
\begin{equation*}
 \begin{bmatrix}
  3 & 0 \\
  0 & 0
 \end{bmatrix}x=
 \begin{bmatrix}
  11 \\
  0
 \end{bmatrix}
\end{equation*}
\begin{equation*}
 x^* = \begin{bmatrix}
        3.6667 \\
        0
       \end{bmatrix}
\end{equation*}
\begin{equation*}
 r^* = \begin{bmatrix}
        1 & 0 \\
        1 & 0 \\
        1 & 0
       \end{bmatrix}
       \begin{bmatrix}
        3.6667 \\
        0
       \end{bmatrix} -
       \begin{bmatrix}
        5 \\
        2 \\
        4
       \end{bmatrix} =
       \begin{bmatrix}
        -1.3333\\
        1.6667 \\
        -0.3333
       \end{bmatrix}
\end{equation*}
\begin{equation*}
 EuclideanNorm = \norm{r}_2 = \sqrt{(-1.3333)^2 + (1.6667)^2 + (-0.3333)^2} = \sqrt{4.6667} \approx 2.1602
\end{equation*}

\begin{equation*}
 SE = \norm{r}_2^2 = (-1.3333)^2 + (1.6667)^2 + (-0.3333)^2 \approx 4.6667
\end{equation*}

\begin{equation*}
 RMSE = \sqrt{\frac{\norm{r}_2^2}{m}} \approx \sqrt{\frac{4.6667}{3}} \approx 1.2472 
\end{equation*}

(b)
\begin{equation*}
\begin{bmatrix}
1 & 0 & 1 & 1 \\
1 & 1 & 2 & 0 \\
0 & 1 & 1 & 1
\end{bmatrix}
\begin{bmatrix}
1 & 1 & 0 \\
0 & 1 & 1 \\
1 & 2 & 1 \\
1 & 0 & 1
\end{bmatrix}
x = \begin{bmatrix}
1 & 0 & 1 & 1 \\
1 & 1 & 2 & 0 \\
0 & 1 & 1 & 1
\end{bmatrix}
\begin{bmatrix}
2 \\
2 \\
3 \\
4
\end{bmatrix}
\end{equation*}

\begin{equation*}
 \begin{bmatrix}
  3 & 3 & 2 \\
  3 & 6 & 3 \\
  2 & 3 & 3
 \end{bmatrix}x = 
 \begin{bmatrix}
  9 \\
  10 \\
  9
 \end{bmatrix}
\end{equation*}

If we re-arrange the formula for ${x^*}$ we get:

\begin{equation}
 x^* = (A^T_2A_2)^{-1}A^T_2b_2
\end{equation}

and the resulting ${x^*}$ will be

\begin{equation*}
 x^* \approx \begin{bmatrix}
        2 \\
        -0.3333 \\
        2
       \end{bmatrix}
\end{equation*}

\begin{equation*}
 r = \begin{bmatrix}
1 & 1 & 0 \\
0 & 1 & 1 \\
1 & 2 & 1 \\
1 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
        2 \\
        -0.3333 \\
        2
\end{bmatrix} -
\begin{bmatrix}
2 \\
2 \\
3 \\
4
\end{bmatrix} \approx
\begin{bmatrix}
-0.3333 \\
-0.3333 \\
0.3333 \\
0
\end{bmatrix}
\end{equation*}

\begin{equation*}
 EuclideanNorm = \norm{r}_2 \approx \sqrt{(-0.3333)^2 + (-0.3333)^2 + (0.3333)^2 + (0)^2} \approx \sqrt{0.3333} \approx 0.5774
\end{equation*}

\begin{equation*}
 SE = \norm{r}_2^2 = (-0.3333)^2 + (-0.3333)^2 + (0.3333)^2 + (0)^2 \approx 0.3333
\end{equation*}

\begin{equation*}
 RMSE = \sqrt{\frac{\norm{r}_2^2}{m}} \approx \sqrt{\frac{0.3333}{4}} \approx 0.2887
\end{equation*}

\section*{Exercise 2: Polynomials models for least squares [20 points]}

\begin{enumerate}[label=(\alph*)]
 \item Write ${leastSquare.m}$ function which calculates least squares ${x^*}$, euclidean norm, SE and RMSE of a matrix A and vector b, and write a script ${ex2a.m}$ which computes the result of exercise 1.\\
 
  \begin{lstlisting}[language=Matlab]
  function [x, EuclideanNorm, SE, RMSE] = leastSquares(A, b)
    x = (A' * A) \ A' * b;
    r = A * x - b;
    EuclideanNorm = norm(r);
    SE = EuclideanNorm ^ 2;
    MSE = SE / length(b);
    RMSE = sqrt(MSE);
  end
 \end{lstlisting}
 
 The code above calculates least squares (${leastSquare.m}$) using matlab library function and Euclidean norm is calculated by using the matlab norm function after calculating the residual vector. Standard Errors (SE) are calculated by directly squaring the Euclidean norm, and before the Root Mean Squared Error (RMSE) is calculated, the Mean Squared Error is calculated through dividing SE by length of vector b. \\
 
 \begin{lstlisting}[language=Matlab]
    A_1 = [1, 0; 1, 0; 1, 0];
    b_1 = [5; 2; 4];
    A_2 = [1, 1, 0; 0, 1, 1; 1, 2, 1; 1, 0, 1];
    b_2 = [2; 2; 3; 4];

    [x_1, norm1, SE1, RMSE1] = leastSquares(A_1, b_1);
    [x_2, norm2, SE2, RMSE2] = leastSquares(A_2, b_2);
 \end{lstlisting}
 
 This particular code (${ex2a.m}$) defines the values of matrix A and vector b as given in the exercise 1, and it calculates and stores the least squares, Euclidean Norm, SE, RMSE using function in ${leastSquare.m}$ as described above. Result of the calculation via the script is same as the calculation by hand for (b) of exercise 1, but it differs for the (a). Reason behind this is because script calculation solves for least squares through utilizing inverse like shown in equation 6, whereas when calculating by hand, an algebric approach is taken. As determinant of ${x}$ is equal to 0, script generates ${NaN}$ and Euclidean Norm, SE, RMSE which are calculated from it also generates NaN. However, algebric approach evades this problem, hence, it produces normal result. A solution to this problem would be checking if least squares generated are ${NaN}$ and if true, we use built-in function such as ${pinv(A) * b}$ and otherwise we use the old inverse calculation approach. \\
 
 Debugged code is as following:
 \begin{lstlisting}[language=Matlab]
    determinant = det(A' * A);
    if (determinant == 0)
        x = pinv(A) * b;
    else
        x = (A' * A) \ A' * b;
    end
    r = A * x - b;
    EuclideanNorm = norm(r);
    SE = EuclideanNorm ^ 2;
    MSE = SE / length(b);
    RMSE = sqrt(MSE);
 \end{lstlisting}

 
 \item Consider the linear model ${y_i = \alpha_1 + \alpha_2x_i}$ and apply it to the crude oil and kerosene production data in the
period 1980-2011. Write a script ${linearModel.m}$ in which you use ${leastSquares()}$ to compute the
least squares solution ${x^*}$ and the metrics of the residual. For each dataset, create a figure in which you plot the original data points and the linear model. \\

 \begin{lstlisting}[language=Matlab]
    [year, production, ~] = readData(filePath);
    
    duration = 2011 - 1980 + 1;

    y = str2double(production);

    x = [ones(duration, 1), year(:)];

    [factors, ~, ~, ~] = leastSquares(x, y);

    z = factors(1) + factors(2) * year(:); %based on y = mx + b;
    
    % plot the line and scatter graph...
 \end{lstlisting}

The code above simply follows the process of reading the data from the file, then converting 'x' and 'y' to viable format of matrix A and vector b, and recaclulating the linear model (line graph) according to the least squares returned and plotting them with the origin (scatter graph). During conversion, columns of the matrix A filled with ${x_i^{columnNumber}}$ (columnNumber starts from 0, and there are only 2 columns) and 'y' is placed as vector b. \\
\vspace{20px}
 \begin{figure}[h!]
    \begin{minipage}[c]{1\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{./figures/ex2b.png}
    \end{minipage}
  \caption{Linear Model and original data of crude oil and kerosene production from 1980 to 2011}
\end{figure}
\vspace{20px}
\item Consider the quadratic model ${y_i = \alpha_1 + \alpha_2x_i + \alpha_3x^2_i}$ and apply it to the crude oil and kerosene production
data in the period 1980-2011. Write a script \textit{quadraticModel.m} in which you use \textit{leastSquares()} to
compute the least squares solution ${x^*}$ and the metrics of the residual. For each dataset, create a figure in which
you plot the original data points and the quadratic model.

The general flow of the logic is very similar, but the matrix A is extended via the same logic so it would produce bigger least square vector (there are 3 columns now). Then instead of ${y_i = mx_i + b}$, quadratic modelling equation ${y_i = a + bx_i + cx_i^2}$ is used. \\
\vspace{20px}
 \begin{lstlisting}[language=Matlab]
    same as before ...
    x = [ones(duration, 1), year(:), year(:).^2];

    [factors, ~, ~, ~] = leastSquares(x, y);

    z = factors(1) + factors(2) * year(:) + factors(3) * year(:).^2;
    same as before ...
 \end{lstlisting}
 As a result of that change, resulting graph (quadratic) became more fitting than the previous linear graph shown in figure 1.
 \vspace{20px}
 \begin{figure}[h!]
    \begin{minipage}[c]{1\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{./figures/ex2c.png}
    \end{minipage}
  \caption{Quadratic Model and original data of crude oil and kerosene production from 1980 to 2011}
\end{figure}

\item Consider the cubic model ${y_i = \alpha_1 + \alpha_2 x_i + \alpha_3 x^2_i + \alpha_4 x^3_i}$ and apply it to the crude oil and kerosene production
data in the period 1980-2011. Write a script \textit{cubicModel.m} in which you use \textit{leastSquares()} to com-
pute the least squares solution ${x^*}$ and the metrics of the residual. For each dataset, create a figure in which you
plot the original data points and the cubic model.

We can apply the same approach as ${(c)}$ and just increase the size of least squares vector and change the slope calculation from ${y_i = a + bx_i + cx_i^2}$, to ${y_i = a + bx_i + cx_i^2 + dx_i^3}$

\newpage

Code can be altered as following: \\

\begin{lstlisting}[language=Matlab]
    x = [ones(duration, 1), year(1:duration), 
                            year(1:duration).^2, 
                            year(1:duration).^3];

    [factors, ~, ~, ~] = leastSquares(x, y(1:duration));

    z = factors(1) + factors(2) * year(1:duration)
                + factors(3) * year(1:duration).^2 
                + factors(4) * year(1:duration).^3;

\end{lstlisting}

Finally, the resultant graph would be more fitted to the original data points than other approaches. Especially for the crude oil production.\\

 \vspace{20px}
 \begin{figure}[h!]
    \begin{minipage}[c]{1\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{./figures/ex2d.png}
    \end{minipage}
  \caption{Cubic Model and original data of crude oil and kerosene production from 1980 to 2011}
\end{figure}
\vspace{20px}

\item Compare the linear, quadratic and cubic models on the basis of the quality metrics computed above, by creating
a table containing the results for the two models. Which one of the three models would you pick for the crude
oil data? And for the kerosene? Provide an estimate of the crude oil and kerosene production in 2012 by using
the three models and compare the values obtained with the real values reported in the data source. Comment on
your results. \\

\newpage

\begin{center}
\begin{tabular}{|l|r|r|r|r|} \hline
Model Type & EuclideanNorm & Standard Error & RMSE \\
\hline
  Linear Crude  & 11,471 & 131,590,000 & 2,027.8\\
\hline
  Quadratic Crude & 9,582.6 & 91,827,000 & 1,694\\
\hline
  Cubic Crude & 7,917.9 & 62,692,000 & 1,399.7 \\
  \hline
  Linear Kerosene & 151.0222 & 22,808 & 26.6972\\
\hline
  Quadratic Kerosene & 145.3013 & 21,112 & 25.6859\\
\hline
  Cubic Kerosene & 138.476 & 19,175 & 24.4793 \\
  \hline
\end{tabular}
\end{center}

\vspace{20px}

\begin{tabular}{|l|r|r|r|r|} \hline
Energy Type & Linear Estimation & Quadratic Estimation & Cubic Estimation & Real Data \\
\hline
 Crude Oil & 17,082(30.3\%) & 14,344(+9.4\%) & 11,473 (-12.5\%) & 13,111\\
\hline
Kerosene & 207.2856(-23.6\%) & 225.1621 (-16.9\%) & 248.4740 (-7.3\%) & 267.89\\
\hline
\end{tabular}
\vspace{20px}

To make a simple analysis, having a smaller Euclidean Norm suggests better fit of the model to the original data as smaller euclidean norm indicates smaller residuals, and naturally bigger would indicate the opposite. Similarly, Standard Error (SE) and Root Mean Squared Error (RMSE) indicates better fit of the model when they are small. \\

Under this assumption, the data on the table suggests for all the cases, cubic model is the best, quadratic model is the second, and linear model is the worst model to fit the original data. \\

However, the prediction made for 2012 from these models suggest, even though cubic model proved to be the best for kerosene production trend prediction, in terms of prediction for crude oil production, quadratic model showed more accurate result. However, prediction of a singular value is not enough to make a conclusion that quadratic model will always perform better for kerosene production prediction or cubic model will always perform better for crude oil production prediction as the 2012 data might have been just a singular anormaly in the data.\\

To get a more concrete conclusion, we would need more historical data and also make more predictions based on the obtained model. However, statistically it is undeniable that cubic model will show the best predictions.\\

\end{enumerate}
\vspace{20px}

\newpage
\section*{Exercise 3: Analysis of periodic data [20 points]}

The file \textit{temperature.txt} contains the area mean-temperatures of Switzerland between January 1864 and March
2021 included. Temperature data exhibit a periodic behaviour and we will try to capture it by using periodic models.
You will need the function \textit{leastSquares()} implemented in Exercise 2. \\

\begin{enumerate}[label=(\alph*)]
 \item Consider the periodic model ${y_i = \alpha_1 + \alpha_2 cos(2\pi x_i ) + \alpha_3 sin(2\pi x_i )}$ and apply it to the temperature data:
(I) between January 1960 and January 1963; (II) between January 1960 and January 1970. Write a script
\textit{periodicA.m} in which you compute the least squares solutions and the metrics of the residual, and plot the
outputs of the model against the original data in both cases. \\

\begin{lstlisting}[language=Matlab]
    [x1, y1] = readTemperatureData(filepath, startYear, endYear);
    x = [ones(length(x1), 1), cos(2 * pi * x1), sin(2 * pi * x1)];
    [factors, ~, ~, ~] = leastSquares(x, y1);
    h = height(x1);

    z = factors(1) + 
        factors(2) * cos(2 * pi * x1(1:h)) + 
        factors(3) * sin(2 * pi * x1(1:h));
    generate graphs...
\end{lstlisting}

The ${temperature.txt}$ file is read in a bit of a different way as the structure of the data is different. It can be seen in ${readTenoeratureData.m}$ file. Then the x-axis data is converted into the periodic model format given in the question. Then the residual vector is calculated using ${leastSquares.m}$ which was completed in the previous question. Then periodic model graph is calculated and graphed along with original data points. The resulting graph is as following: \\

 \begin{figure}[h!]
    \begin{minipage}[c]{1\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{./figures/ex3a.png}
    \end{minipage}
  \caption{Periodic model of swiss weather 1960 Jan to 1963 Jan (left) and 1960 Jan to 1970 Jan (right)}
\end{figure}

\newpage

\item Repeat the same analysis and plots of the previous point for both time series, by using the periodic model
${y_i = \alpha_1 + \alpha_2 cos(2\pi x_i ) + \alpha_3 sin(2\pi x_i ) + \alpha_4 cos(4\pi x_i)}$ in the script \textit{periodicB.m}.

Only things that need to be added are as following:

\begin{lstlisting}[language=Matlab]
    ...
    x = [ones(length(x1), 1), cos(2 * pi * x1), 
         sin(2 * pi * x1), cos(4 * pi * x1)];
    ...
    z = factors(1) + 
        factors(2) * cos(2 * pi * x1(1:h)) + 
        factors(3) * sin(2 * pi * x1(1:h)) +
        factors(4) * cos(4 * pi * x1(1:h));
    ...
\end{lstlisting}

 \begin{figure}[h!]
    \begin{minipage}[c]{1\linewidth}
        \centering
        \includegraphics[width=0.9\linewidth]{./figures/ex3b.png}
    \end{minipage}
  \caption{Periodic model of swiss weather 1960 Jan to 1963 Jan (left) and 1960 Jan to 1970 Jan (right)}
\end{figure}
\end{enumerate}

\section*{Exercise 4: Data linearization and Levenberg-Marquardt method for the exponential model [20 points]}

\section*{Exercise 5: Tikhonov regularization [15 points]}



\end{document}
